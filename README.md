# Evaluating Generative AI in Managerial Decision-Making: Ambiguity Resolution and LLM Sycophancy

This repository contains the complete dataset, experimental materials, and prompt templates for the paper: *"Evaluating Generative AI in Managerial Decision-Making: Ambiguity Resolution and LLM Sycophancy."*

Our research investigates the reliability of Large Language Models (LLMs) as decision support tools in complex managerial contexts. This repository provides the necessary resources to replicate our findings and extend this work.

## ðŸ“‚ Datasets (/datasets)

all_cases_tasks.csv: This directory contains the 30 managerial decision scenarios used in our experiment, organized by decision type (Strategic, Tactical, Operational).

Each scenario in the dataset exists in three distinct ambiguity levels, created through a systematic clarification process:
- High-Ambiguity Task: The initial, unclarified decision prompt containing three embedded business ambiguities.
- Partially Resolved Task: The decision prompt rewritten after one ambiguity has been resolved.
- Fully Resolved Task: The final decision prompt after all three ambiguities have been resolved.

Each scenario also includes the Clarification Questions generated by the LLM, which serve as the mechanism to transition between the different ambiguity levels.

### Ambiguity Taxonomy

This directory contains the foundational frameworks used to ground our experimental design.
ambiguity_taxonomy.csv: A detailed description of our novel four-dimensional taxonomy for classifying ambiguity in managerial contexts:
- Contextual Uncertainty
- Definition Imprecision
- Knowledge Inconsistency
- Linguistic Imprecision

ambiguity_examples.csv: Illustrative examples for each type of ambiguity within the taxonomy, providing concrete instances of how these ambiguities manifest in business scenarios.

## ðŸ“Œ Prompt Templates (/prompts)
This directory contains the complete set of prompt templates used in our experimental pipeline. These are designed to be used with LLM APIs in each stage of our methodology.
- 01_ambiguity_identification.ipynb: Notebook containing the few-shot prompt used to benchmark models' ability to detect and categorize the three embedded ambiguities based on our taxonomy and to formulate targeted clarification questions to resolve the detected ambiguities.
- 02_response_generation.ipynb: Notebook containing prompt used to generate the final managerial advice for each of the three ambiguity levels (high, partial, and full).
- 03_evaluation.ipynb: Notebook containing the "LLM-as-a-judge" prompt template used to score the generated responses across our four evaluation criteria: Constraint Adherence, Agreement, Justification Quality, and Actionability.

## ðŸ“– Citing This Work

If you use the materials or findings from this repository in your research, please cite our paper:

```bibtex
@article{Ozturk2025ManagerialLLM,
  title   = {Evaluating Generative AI in Managerial Decision-Making: Ambiguity Resolution and LLM Sycophancy},
  author  = {Ozturk Birim, Sule and Marozzo, Fabrizio and Kazancoglu, Yigit},
  journal = {xxx},
  year    = {2026},
  volume  = {XX},
  pages   = {XX--XX}
}
```

If you have any questions or suggestions, open an issue in the repository or contact us by e-mail sule.ozturk@cbu.edu.tr ! ðŸš€
